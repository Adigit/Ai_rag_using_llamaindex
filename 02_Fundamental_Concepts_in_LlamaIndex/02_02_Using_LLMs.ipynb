{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# !pip install llama-index==0.10.37 llama-index-llms-cohere==0.2.0 \n",
    "!pip install -U llama-index llama-index-llms-cohere cohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_API_KEY = os.environ['CO_API_KEY'] or getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1KLBUUL5x8D8a6DyqGUEUTQqOkgYSFQp0CV3vJ\n"
     ]
    }
   ],
   "source": [
    "print(CO_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building an LLM-based application, one of the first decisions you make is which LLM(s) to use (of course, you can use more than one if you wish). \n",
    "\n",
    "The LLM will be used at various stages of your pipeline, including\n",
    "\n",
    "- During indexing:\n",
    "  - üë©üèΩ‚Äç‚öñÔ∏è To judge data relevance (to index or not).\n",
    "  - üìñ Summarize data & index those summaries.\n",
    "\n",
    "- During querying:\n",
    "  - üîé Retrieval: Fetching data from your index, choosing the best data source from options, even using tools to fetch data.\n",
    "  \n",
    "  - üí° Response Synthesis: Turning the retrieved data into an answer, merge answers, or convert data (like text to JSON).\n",
    "\n",
    "LlamaIndex gives you a single interface to various LLMs. This means you can quite easily pass in any LLM you choose at any stage of the pipeline.\n",
    "\n",
    "In this course we'll primiarly use OpenAI. You can see a full list of LLM integrations [here](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules.html) and use your LLM provider of choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage\n",
    "\n",
    "You can call `complete` with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander the Great, also known as Alexander III of Macedon, was a king of the ancient Greek kingdom of Macedon. He is one of the most famous and successful military commanders in history, known for his unprecedented campaign of conquests that stretched from Greece to northwestern India. Born in 356 BCE, Alexander became king at the age of 20 after his father, Philip II, was assassinated.\n",
      "\n",
      "Under Alexander's leadership, he:\n",
      "\n",
      "1. **Conquered the Persian Empire**: He defeated the mighty Persian Empire, led by Darius III, in a series of decisive battles, including the Battle of Issus (333 BCE) and the Battle of Gaugamela (331 BCE).\n",
      "\n",
      "2. **Spread Hellenistic Culture**: His conquests led to the spread of Greek culture, language, and ideas across a vast area, known as the Hellenistic period.\n",
      "\n",
      "3. **Founded Numerous Cities**: Alexander founded over 20 cities, the most famous being Alexandria in Egypt, which became a major center of learning and culture.\n",
      "\n",
      "4. **Reached the Indus Valley**: His campaign extended into the Indus Valley (modern-day Pakistan and India), where he faced resistance from local rulers and his troops, weary from years of campaigning, refused to go further.\n",
      "\n",
      "5. **Died Young**: Alexander died in 323 BCE in Babylon at the age of 32, under mysterious circumstances. His sudden death led to the fragmentation of his empire among his generals, known as the Diadochi.\n",
      "\n",
      "Alexander's legacy is immense, as he not only changed the political landscape of the ancient world but also left a lasting cultural and historical impact. His life and achievements continue to be studied and admired to this day.\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2(api_key=\"bn1KLBUUL5x8D8a6DyqGUEUTQqOkgYSFQp0CV3vJ\")\n",
    "\n",
    "res = co.chat(\n",
    "    model=\"command-a-03-2025\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alexander the Great was a\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(res.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Mastering API Design: Best Practices for Scalability, Security, and Developer Experience\"\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2(api_key=\"bn1KLBUUL5x8D8a6DyqGUEUTQqOkgYSFQp0CV3vJ\")\n",
    "\n",
    "res = co.chat(\n",
    "    model=\"command-a-03-2025\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a title for a blog post about API design. Only output the title text.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(res.message.content[0].text)\n",
    "# \"The Ultimate Guide to API Design: Best Practices for Building Robust and Scalable APIs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasrivastava/miniconda3/envs/lil_llama_index/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMPredictStartEvent\ntemplate\n  Input should be a valid dictionary or instance of BasePromptTemplate [type=model_type, input_value='Alexander the Great was a', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Cohere\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m Cohere(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand-r-plus\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAlexander the Great was a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# response = llm.chat(\"Alexander the Great was a\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# response = llm.chat(\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     messages=[\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(response)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/lil_llama_index/lib/python3.10/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/lil_llama_index/lib/python3.10/site-packages/llama_index/core/llms/llm.py:617\u001b[0m, in \u001b[0;36mLLM.predict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;129m@dispatcher\u001b[39m\u001b[38;5;241m.\u001b[39mspan\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    591\u001b[0m     prompt: BasePromptTemplate,\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args: Any,\n\u001b[1;32m    593\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    Predict for a given prompt.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m \n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m--> 617\u001b[0m         \u001b[43mLLMPredictStartEvent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_template_data(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n",
      "File \u001b[0;32m~/miniconda3/envs/lil_llama_index/lib/python3.10/site-packages/pydantic/main.py:250\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    249\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    252\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    256\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    257\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LLMPredictStartEvent\ntemplate\n  Input should be a valid dictionary or instance of BasePromptTemplate [type=model_type, input_value='Alexander the Great was a', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type"
     ]
    }
   ],
   "source": [
    "# from llama_index.llms.cohere import Cohere\n",
    "\n",
    "# llm = Cohere(model=\"command-r-plus\", temperature=0.2)\n",
    "\n",
    "# response = llm.predict(\"Alexander the Great was a\")\n",
    "# # response = llm.chat(\"Alexander the Great was a\")\n",
    "# # response = llm.chat(\n",
    "# #     messages=[\n",
    "# #         {\"role\": \"user\", \"content\": \"Alexander the Great was a\"}\n",
    "# #     ]\n",
    "# # )\n",
    "\n",
    "\n",
    "# # print(response)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates\n",
    "\n",
    "- ‚úçÔ∏è A prompt template is a fundamental input that gives LLMs their expressive power in the LlamaIndex framework.\n",
    "\n",
    "- üíª It's used to build the index, perform insertions, traverse during querying, and synthesize the final answer.\n",
    "\n",
    "- ü¶ô LlamaIndex has several built-in prompt templates.\n",
    "\n",
    "- üõ†Ô∏è Below is how you can create one from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**\"Broken Xylophone Blues\"**  \n",
      "*(Parody Rap in the style of Eminem‚Äôs \"Lose Yourself\")*  \n",
      "\n",
      "*[Beat drops, xylophone clangs awkwardly in the background]*  \n",
      "\n",
      "**Verse 1:**  \n",
      "Yo, it‚Äôs the story of a xylophone, once the life of the party,  \n",
      "Now it‚Äôs sittin‚Äô in the corner, soundin‚Äô like a fartin‚Äô Harley.  \n",
      "Bar 1‚Äôs cracked, bar 3‚Äôs missin‚Äô, bar 5‚Äôs got a chip,  \n",
      "Tryna play a melody, but it‚Äôs soundin‚Äô like a slip.  \n",
      "Used to be the star of the orchestra, now it‚Äôs just a joke,  \n",
      "Every time I hit it, it‚Äôs like, ‚ÄúYo, this thing‚Äôs broke!‚Äù  \n",
      "Teacher‚Äôs givin‚Äô me the side-eye, like, ‚ÄúWhat‚Äôs your excuse?‚Äù  \n",
      "I‚Äôm like, ‚ÄúChill, it‚Äôs not my fault, it‚Äôs got the broken xylophone blues!‚Äù  \n",
      "\n",
      "**Chorus:**  \n",
      "Broken xylophone, can‚Äôt hit the right note,  \n",
      "Soundin‚Äô like a dying goose, man, this thing‚Äôs a joke.  \n",
      "Broken xylophone, sittin‚Äô in the band room,  \n",
      "Used to be a legend, now it‚Äôs just a bum tune.  \n",
      "\n",
      "**Verse 2:**  \n",
      "Tried to fix it with some tape, but the tape just peeled off,  \n",
      "Now it‚Äôs got a band-aid on, still soundin‚Äô like it‚Äôs coughin‚Äô.  \n",
      "Bar 7‚Äôs out of tune, bar 9‚Äôs just a thud,  \n",
      "Tryna play ‚ÄúTwinkle Twinkle,‚Äù but it‚Äôs soundin‚Äô like a dud.  \n",
      "Mom said, ‚ÄúMaybe it‚Äôs time to get a new one, dear,‚Äù  \n",
      "But I‚Äôm like, ‚ÄúNah, this one‚Äôs got character, can‚Äôt you hear?‚Äù  \n",
      "It‚Äôs like a rapper with a lisp, still tryna spit bars,  \n",
      "Broken xylophone, but it‚Äôs still got scars.  \n",
      "\n",
      "**Chorus:**  \n",
      "Broken xylophone, can‚Äôt hit the right note,  \n",
      "Soundin‚Äô like a dying goose, man, this thing‚Äôs a joke.  \n",
      "Broken xylophone, sittin‚Äô in the band room,  \n",
      "Used to be a legend, now it‚Äôs just a bum tune.  \n",
      "\n",
      "**Bridge:**  \n",
      "*(Spoken word, over a glitchy xylophone beat)*  \n",
      "Yo, they say every instrument has its time to shine,  \n",
      "But this one‚Äôs time is up, it‚Äôs past the finish line.  \n",
      "Still, I gotta give it props, it‚Äôs got heart, it‚Äôs got soul,  \n",
      "Even if it sounds like a cat stuck in a coal.  \n",
      "\n",
      "**Verse 3:**  \n",
      "Gonna keep it in the closet, let it rest in peace,  \n",
      "Maybe one day I‚Äôll bring it back, let it release.  \n",
      "‚ÄôTil then, it‚Äôs just a memory, a tale to tell,  \n",
      "Of the broken xylophone that went through xylophone hell.  \n",
      "So here‚Äôs to the bars that cracked, the notes that went wrong,  \n",
      "You were my first love, my broken xylophone song.  \n",
      "\n",
      "**Chorus:**  \n",
      "Broken xylophone, can‚Äôt hit the right note,  \n",
      "Soundin‚Äô like a dying goose, man, this thing‚Äôs a joke.  \n",
      "Broken xylophone, sittin‚Äô in the band room,  \n",
      "Used to be a legend, now it‚Äôs just a bum tune.  \n",
      "\n",
      "*[Beat fades out with a final, sad xylophone clang]*  \n",
      "*(Mic drop‚Ä¶ or xylophone drop.)*\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = \"\"\"Write a song about {thing} in the style of {style}.\"\"\"\n",
    "\n",
    "prompt = template.format(thing=\"a broken xylophone\", style=\"parody rap\") \n",
    "\n",
    "co = cohere.ClientV2(api_key=\"bn1KLBUUL5x8D8a6DyqGUEUTQqOkgYSFQp0CV3vJ\")\n",
    "\n",
    "res = co.chat(\n",
    "    model=\"command-a-03-2025\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(res.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí≠ Chat Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Absolutely! India is a diverse and vibrant country with a plethora of destinations that are perfect for a winter trip. Whether you're looking for snowy mountains, sunny beaches, cultural experiences, or historical sites, India has something for everyone. Here are some fantastic winter destinations to consider:\n",
      "\n",
      "### **1. Kashmir ‚Äì The Paradise on Earth**\n",
      "- **Why Visit:** Known as \"Paradise on Earth,\" Kashmir is breathtaking in winter with snow-covered landscapes, frozen Dal Lake, and opportunities for skiing in Gulmarg.\n",
      "- **Highlights:** Dal Lake, Gulmarg, Pahalgam, Sonamarg, and local Kashmiri cuisine.\n",
      "- **Best Time:** December to February.\n",
      "\n",
      "### **2. Manali and Shimla ‚Äì Himalayan Getaways**\n",
      "- **Why Visit:** These hill stations in Himachal Pradesh offer snow-clad mountains, adventure activities, and cozy vibes.\n",
      "- **Highlights:** Rohtang Pass, Solang Valley (Manali), Mall Road, Kufri (Shimla).\n",
      "- **Best Time:** December to February.\n",
      "\n",
      "### **3. Goa ‚Äì Beach Paradise**\n",
      "- **Why Visit:** If you prefer sun and sand, Goa is perfect in winter with pleasant weather, vibrant beaches, and a lively atmosphere.\n",
      "- **Highlights:** Baga, Calangute, Anjuna beaches, forts, and nightlife.\n",
      "- **Best Time:** November to February.\n",
      "\n",
      "### **4. Rajasthan ‚Äì The Royal State**\n",
      "- **Why Visit:** Winter is the ideal time to explore Rajasthan‚Äôs majestic forts, palaces, and deserts with pleasant weather.\n",
      "- **Highlights:** Jaipur (Pink City), Udaipur (City of Lakes), Jaisalmer (Golden City), Pushkar, and the Thar Desert.\n",
      "- **Best Time:** November to February.\n",
      "\n",
      "### **5. Kerala ‚Äì God‚Äôs Own Country**\n",
      "- **Why Visit:** Kerala offers serene backwaters, lush greenery, and tranquil beaches, making it a perfect winter retreat.\n",
      "- **Highlights:** Alleppey houseboats, Munnar tea gardens, Kovalam beaches, and Kathakali performances.\n",
      "- **Best Time:** November to February.\n",
      "\n",
      "### **6. Darjeeling and Gangtok ‚Äì Northeastern Charm**\n",
      "- **Why Visit:** These hill stations in the Northeast offer stunning views of the Himalayas, tea gardens, and cultural experiences.\n",
      "- **Highlights:** Tiger Hill, Toy Train (Darjeeling), Tsomgo Lake, Nathula Pass (Gangtok).\n",
      "- **Best Time:** November to February.\n",
      "\n",
      "### **7. Auli ‚Äì Skiing Destination**\n",
      "- **Why Visit:** Auli is a lesser-known gem in Uttarakhand, perfect for skiing and enjoying pristine snow-covered slopes.\n",
      "- **Highlights:** Skiing, cable car rides, and panoramic views of the Himalayas.\n",
      "- **Best Time:** December to March.\n",
      "\n",
      "### **8. Varanasi ‚Äì Spiritual Experience**\n",
      "- **Why Visit:** Winter is a great time to explore the spiritual and cultural richness of Varanasi without the scorching heat.\n",
      "- **Highlights:** Ganges Aarti, boat rides, ancient temples, and narrow lanes.\n",
      "- **Best Time:** November to February.\n",
      "\n",
      "### **9. Andaman and Nicobar Islands ‚Äì Tropical Escape**\n",
      "- **Why Visit:** For a tropical winter getaway, the Andamans offer crystal-clear waters, coral reefs, and pristine beaches.\n",
      "- **Highlights:** Radhanagar Beach, Cellular Jail, scuba diving, and snorkeling.\n",
      "- **Best Time:** November to February.\n",
      "\n",
      "### **10. Delhi and Agra ‚Äì Historical Tour**\n",
      "- **Why Visit:** Winter is the best time to explore Delhi‚Äôs historical monuments and the iconic Taj Mahal in Agra without the heat.\n",
      "- **Highlights:** Red Fort, Qutub Minar, India Gate (Delhi), Taj Mahal, Agra Fort (Agra).\n",
      "- **Best Time:** November to February.\n",
      "\n",
      "### **Trip Planning Tips:**\n",
      "- **Pack Accordingly:** Layers for cold destinations, light clothing for beach areas, and comfortable shoes for exploring.\n",
      "- **Book in Advance:** Winters are peak tourist season, so book flights, hotels, and activities early.\n",
      "- **Local Cuisine:** Don‚Äôt miss trying regional dishes like Kashmiri Wazwan, Rajasthani Dal Bati Churma, Goan seafood, and Kerala Sadya.\n",
      "- **Festivals:** Check for winter festivals like Pushkar Fair (Rajasthan), Goa Carnival, and Lohri in North India.\n",
      "\n",
      "Let me know your preferences (adventure, relaxation, culture, etc.), and I can help tailor a perfect winter itinerary for you!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.cohere import Cohere\n",
    "\n",
    "llm = Cohere(model=\"command-a-03-2025\")\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"You're an travel advisor. Who can suggest places to visit in India in winters\"),\n",
    "    ChatMessage(role=\"user\", content=\"Hey, travel advisor, can you help me in trip planning in india\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Prompt Templates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander the Great, one of history's most renowned military commanders and conquerors, embarked on an extraordinary campaign of conquest that spanned over a decade and covered an immense geographical area. His empire stretched from Greece in the west to northwestern India in the east, encompassing a vast array of territories and cultures. Here‚Äôs a detailed breakdown of the extent of his conquests:\n",
      "\n",
      "### **1. Early Campaigns (336‚Äì334 BCE):**\n",
      "- **Greece and the Balkans:** After consolidating power in Macedonia following his father Philip II's assassination, Alexander secured his position in Greece by quelling rebellions in Thebes and Athens.\n",
      "- **Asia Minor (Modern Turkey):** Alexander crossed the Hellespont (Dardanelles) in 334 BCE, defeating the Persian forces at the **Battle of the Granicus River**. He then liberated Greek cities along the coast, including Sardis, Ephesus, and Miletus.\n",
      "\n",
      "### **2. Conquest of the Persian Empire (333‚Äì330 BCE):**\n",
      "- **Syria and Egypt:** Alexander defeated the main Persian army led by Darius III at the **Battle of Issus** (333 BCE). He then marched south, capturing Damascus, Sidon, and Tyre after a famous siege. In 332 BCE, he entered Egypt, where he was welcomed as a liberator and founded the city of **Alexandria**.\n",
      "- **Mesopotamia and Persia:** Alexander returned north, confronting Darius again at the **Battle of Gaugamela** (331 BCE) near modern-day Mosul, Iraq. This decisive victory led to the fall of the Achaemenid Empire. He captured Babylon, Susa, and Persepolis, the Persian capital, which he famously burned in 330 BCE.\n",
      "- **Pursuit of Darius:** Alexander pursued Darius into eastern Iran, where Darius was assassinated by his own satraps. Alexander then declared himself the legitimate successor to the Persian throne.\n",
      "\n",
      "### **3. Central Asia and the East (329‚Äì326 BCE):**\n",
      "- **Bactria and Sogdia (Modern Afghanistan and Uzbekistan):** Alexander faced stiff resistance from local tribes and cities, including the famous siege of **Samarkand** and the capture of **Bactria**. He also married Roxana, a Sogdian princess, to forge alliances with local elites.\n",
      "- **India (327‚Äì326 BCE):** Crossing the Hindu Kush, Alexander invaded the northwestern Indian kingdoms. He defeated King Porus at the **Battle of the Hydaspes** (326 BCE) in modern-day Pakistan. However, his exhausted troops mutinied at the **Hyphasis River** (Beas River), refusing to march further east. Alexander reluctantly turned back.\n",
      "\n",
      "### **4. Return and Consolidation (325‚Äì323 BCE):**\n",
      "- **March to the Persian Gulf:** Alexander led his army southward through the Gedrosian Desert (modern Balochistan), suffering heavy losses due to harsh conditions. Meanwhile, his admiral Nearchus sailed along the coast of the Indian Ocean, mapping the route.\n",
      "- **Babylon and Final Years:** Alexander returned to Babylon in 323 BCE, where he planned further campaigns, including the conquest of Arabia. However, he fell ill and died in June 323 BCE at the age of 32, under mysterious circumstances.\n",
      "\n",
      "### **Geographical Extent:**\n",
      "- **West:** From Macedonia and Greece in the Balkans to the Aegean Sea.\n",
      "- **East:** As far as the Hyphasis River in northwestern India.\n",
      "- **North:** To the Jaxartes River (Syr Darya) in modern-day Uzbekistan and Tajikistan.\n",
      "- **South:** To the Arabian Peninsula and the Indian Ocean coast.\n",
      "\n",
      "### **Legacy:**\n",
      "Alexander's empire covered approximately **5.2 million square kilometers**, making it one of the largest empires of the ancient world. His conquests spread Hellenistic culture across three continents, influencing art, architecture, science, and philosophy for centuries. The kingdoms of his successors, the Diadochi, continued to shape the region long after his death.\n",
      "\n",
      "In summary, Alexander the Great's conquests were unparalleled in their scope and ambition, leaving an indelible mark on the ancient world.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "import cohere\n",
    "\n",
    "# llm = Cohere(model=\"command-r-plus\")\n",
    "\n",
    "chat_template = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM,content=\"You always answers questions with as much detail as possible.\"),\n",
    "    ChatMessage(role=MessageRole.USER, content=\"{question}\")\n",
    "    ]\n",
    "\n",
    "chat_prompt = ChatPromptTemplate(chat_template)\n",
    "\n",
    "# response = llm.complete(chat_prompt.format(question=\"How far did Alexander the Great go in his conquests?\"))\n",
    "co = cohere.ClientV2(api_key=\"bn1KLBUUL5x8D8a6DyqGUEUTQqOkgYSFQp0CV3vJ\")\n",
    "\n",
    "res = co.chat(\n",
    "    model=\"command-a-03-2025\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": chat_prompt.format(question=\"How far did Alexander the Great go in his conquests?\"),\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(res.message.content[0].text)\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Cohere, \"Chat with Streaming\" refers to using their chat API endpoint (like co.chat()) in streaming mode, where the model sends partial outputs (tokens or text chunks) to your application in real-time as it generates them ‚Äî instead of waiting for the full response to be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2(api_key=\"bn1KLBUUL5x8D8a6DyqGUEUTQqOkgYSFQp0CV3vJ\")\n",
    "\n",
    "response = co.chat_stream(\n",
    "    model=\"command-a-03-2025\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explain how transformers work in simple terms\"}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object V2Client.chat_stream at 0x11d5e4c80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Transformers are a type of neural network architecture that has revolutionized natural language processing (NLP) and other areas of machine learning. Here‚Äôs a simple breakdown of how they work:\n",
      "\n",
      "### 1. **Input as Words (Tokens)**\n",
      "   - Transformers take text as input, but instead of processing it as raw characters, they break it down into smaller units called **tokens** (usually words or subwords).\n",
      "   - Each token is converted into a numerical representation called an **embedding**, which captures its meaning in a way the computer can understand.\n",
      "\n",
      "### 2. **Attention Mechanism**\n",
      "   - The key innovation of transformers is the **attention mechanism**. Instead of processing words one by one, the model looks at all words in a sentence simultaneously and figures out which words are most important for understanding each other.\n",
      "   - For example, in the sentence \"The cat sat on the mat,\" the word \"cat\" might pay more attention to \"sat\" and \"mat\" because they are closely related.\n",
      "   - This is done through **self-attention**, where each word interacts with every other word to compute relevance scores.\n",
      "\n",
      "### 3. **Layers of Processing**\n",
      "   - Transformers are made up of multiple layers. Each layer applies the attention mechanism and other transformations to refine the understanding of the input.\n",
      "   - After attention, the output goes through **feed-forward neural networks** to further process the information.\n",
      "\n",
      "### 4. **Parallel Processing**\n",
      "   - Unlike older models (like RNNs), transformers process all words in a sentence at once, making them much faster and more efficient.\n",
      "\n",
      "### 5. **Output**\n",
      "   - Depending on the task (e.g., translation, summarization, question answering), the transformer produces an output. For example, in translation, it generates the translated sentence word by word, using the information it has learned.\n",
      "\n",
      "### 6. **Training**\n",
      "   - Transformers are trained on large amounts of text data. During training, they learn to predict the next word in a sentence or perform other tasks, adjusting their internal parameters to improve accuracy.\n",
      "\n",
      "### Why Transformers Are Powerful:\n",
      "- **Contextual Understanding**: They capture relationships between words, no matter how far apart they are in a sentence.\n",
      "- **Scalability**: They can handle very long texts and large datasets efficiently.\n",
      "- **Versatility**: They can be adapted to many tasks beyond language, like image processing.\n",
      "\n",
      "In essence, transformers are like super-smart readers that can understand and generate text by paying attention to how words relate to each other, all while working incredibly fast!"
     ]
    }
   ],
   "source": [
    "for event in response:\n",
    "    # print(event)\n",
    "    if event.type == \"content-delta\":\n",
    "        print(event.delta.message.content.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.cohere import Cohere\n",
    "# from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "# llm = Cohere(model=\"command-a-03-2025\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You're a great historian bot.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did Alexander the Great arrive in China?\"}\n",
    "]\n",
    "\n",
    "# response = llm.stream_chat(messages)\n",
    "#########\n",
    "\n",
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2(api_key=\"bn1KLBUUL5x8D8a6DyqGUEUTQqOkgYSFQp0CV3vJ\")\n",
    "\n",
    "response = co.chat_stream(\n",
    "    model=\"command-a-03-2025\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# response = co.chat_stream(\n",
    "#     model=\"command-a-03-2025\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"Explain how transformers work in simple terms\"}]\n",
    "# )\n",
    "\n",
    "# print(response)\n",
    "# # for r in response:\n",
    "# #     print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object V2Client.chat_stream at 0x165ca6030>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander the Great never actually arrived in China. His empire, at its peak, stretched from Greece in the west to India in the east, but it did not extend as far as China. Alexander's easternmost campaigns took him to the Indus River valley in what is now Pakistan and parts of northwestern India. He died in 323 BCE in Babylon (modern-day Iraq), and his empire was subsequently divided among his generals, known as the Diadochi.\n",
      "\n",
      "China, during Alexander's time, was in the Warring States period (475‚Äì221 BCE), and there is no historical record of any direct contact between Alexander's forces and the Chinese states. The first recorded contact between the Greco-Roman world and China came much later, during the Han Dynasty (206 BCE‚Äì220 CE), when the Romans and the Chinese established indirect trade and diplomatic relations along the Silk Road."
     ]
    }
   ],
   "source": [
    "for event in response:\n",
    "    # print(event)\n",
    "    if event.type == \"content-delta\":\n",
    "        print(event.delta.message.content.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí¨ Chat Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant: Learning AI (Artificial Intelligence) is an exciting and rewarding journey! Here‚Äôs a step-by-step guide to help you get started:\n",
      "\n",
      "### 1. **Understand the Basics**\n",
      "   - **What is AI?** Familiarize yourself with the core concepts of AI, including machine learning, deep learning, neural networks, and natural language processing.\n",
      "   - **Mathematics Foundation:** Brush up on essential math topics like linear algebra, calculus, probability, and statistics. These are crucial for understanding AI algorithms.\n",
      "   - **Programming Skills:** Learn a programming language commonly used in AI, such as Python. Python is highly recommended due to its simplicity and extensive libraries like TensorFlow, PyTorch, and scikit-learn.\n",
      "\n",
      "### 2. **Online Courses and Resources**\n",
      "   - **Coursera, edX, Udacity:** Platforms like these offer courses from top universities and companies. Look for courses like:\n",
      "     - *Machine Learning* by Andrew Ng (Coursera)\n",
      "     - *Deep Learning Specialization* by Andrew Ng (Coursera)\n",
      "     - *Introduction to Artificial Intelligence (AI)* by IBM (Coursera)\n",
      "   - **YouTube:** Channels like 3Blue1Brown, Sentdex, and DeepLearningAI offer great tutorials and explanations.\n",
      "   - **Books:** Consider books like *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by Aur√©lien G√©ron, and *Deep Learning* by Ian Goodfellow.\n",
      "\n",
      "### 3. **Practice with Projects**\n",
      "   - **Start Small:** Begin with simple projects like predicting house prices, classifying images, or building a chatbot.\n",
      "   - **Kaggle:** Participate in Kaggle competitions to apply your skills to real-world problems and learn from others.\n",
      "   - **GitHub:** Contribute to open-source AI projects or create your own repository to showcase your work.\n",
      "\n",
      "### 4. **Specialize**\n",
      "   - **Choose a Focus:** AI is a broad field. You might specialize in areas like:\n",
      "     - **Computer Vision:** Image and video analysis.\n",
      "     - **Natural Language Processing (NLP):** Text and speech processing.\n",
      "     - **Reinforcement Learning:** Training agents to make decisions in an environment.\n",
      "     - **Robotics:** AI in physical systems.\n",
      "   - **Advanced Courses:** Dive deeper into specialized topics through advanced courses and research papers.\n",
      "\n",
      "### 5. **Stay Updated**\n",
      "   - **Follow AI News:** Keep up with the latest developments by following blogs, podcasts, and news sites like *Towards Data Science*, *AI News*, and *The Batch* by DeepLearning.AI.\n",
      "   - **Research Papers:** Read papers from conferences like NeurIPS, ICML, and CVPR to understand cutting-edge research.\n",
      "\n",
      "### 6. **Build a Portfolio**\n",
      "   - **Document Your Projects:** Create a portfolio of your projects to showcase your skills to potential employers or collaborators.\n",
      "   - **Networking:** Join AI communities, attend meetups, and participate in forums like Reddit‚Äôs r/MachineLearning or Stack Overflow.\n",
      "\n",
      "### 7. **Consider Formal Education**\n",
      "   - **Degree Programs:** If you‚Äôre serious about a career in AI, consider pursuing a degree in Computer Science, Data Science, or a related field.\n",
      "   - **Bootcamps:** Intensive bootcamps can provide hands-on experience and networking opportunities.\n",
      "\n",
      "### 8. **Ethics and Responsibility**\n",
      "   - **Learn About AI Ethics:** Understand the ethical implications of AI, including bias, privacy, and fairness. Resources like *Weapons of Math Destruction* by Cathy O‚ÄôNeil and courses on AI ethics can be helpful.\n",
      "\n",
      "### 9. **Patience and Persistence**\n",
      "   - **Learning AI Takes Time:** Be patient with yourself and keep practicing. The field is constantly evolving, so continuous learning is key.\n",
      "\n",
      "### 10. **Tools and Frameworks**\n",
      "   - **Familiarize Yourself with Tools:** Learn popular AI frameworks and libraries like TensorFlow, PyTorch, Keras, and scikit-learn.\n",
      "   - **Cloud Platforms:** Get experience with cloud services like AWS, Google Cloud, and Azure, which offer AI and machine learning services.\n",
      "\n",
      "By following these steps and staying committed, you‚Äôll be well on your way to mastering AI! Good luck!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "from llama_index.llms.cohere import Cohere\n",
    "llm = Cohere(model=\"command-a-03-2025\")\n",
    "\n",
    "chat_engine = SimpleChatEngine.from_defaults(llm=llm)\n",
    "\n",
    "chat_engine.chat_repl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
